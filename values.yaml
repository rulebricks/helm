# =============================================================================
# STORAGE CLASS (AWS EBS gp3)
# Creates a gp3 StorageClass if it doesn't exist
# =============================================================================
storageClass:
  create: true
  name: gp3
  provisioner: ebs.csi.aws.com
  type: gp3
  fsType: ext4
  reclaimPolicy: Delete
  volumeBindingMode: WaitForFirstConsumer
  allowVolumeExpansion: true

# =============================================================================
# GLOBAL SETTINGS
# These values are used across multiple components and should be set here
# =============================================================================
global:
  # Domain for ingress and TLS certificate generation
  domain: "helmtest.rulebricks.com"
  # Email for TLS certificate registration (required for cert-manager)
  email: "support@rulebricks.com"
  # License Key for Rulebricks Enterprise
  licenseKey: "evaluation"
  # 2 Phase TLS setupâ€“ keep this `false` initially
  # You will automatically be prompted to upgrade with `true` after you install the chart
  tlsEnabled: false

  # Automated Database Migrations
  # Set to false if using an external Supabase instance (you must run migrations manually)
  migrations:
    enabled: true

  # SMTP Configuration (Required for user invitations and password resets)
  smtp:
    host: "smtp.mailtrap.io"
    port: 2525
    user: "demo-user"
    pass: "demo-password"
    from: "no-reply@rulebricks.com"
    fromName: "Rulebricks"

  # Supabase Configuration (used by both Rulebricks app and self-hosted Supabase)
  # JWTs must be valid HS256 tokens signed with the jwtSecret below.
  # These are demo tokens signed with "super-secret-jwt-token-change-me".
  # REPLACE THESE for production!
  supabase:
    # Leave empty to auto-discover from the supabase subchart (recommended)
    # Only set explicitly if using an external Supabase instance
    url: ""
    anonKey: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyAgCiAgICAicm9sZSI6ICJhbm9uIiwKICAgICJpc3MiOiAic3VwYWJhc2UtZGVtbyIsCiAgICAiaWF0IjogMTY0MTc2OTIwMCwKICAgICJleHAiOiAxNzk5NTM1NjAwCn0.dc_X5iR_VP_qT0zsiyj_I_OZ2T9FtRU2BBNWN8Bu4GE"
    serviceKey: "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyAgCiAgICAicm9sZSI6ICJzZXJ2aWNlX3JvbGUiLAogICAgImlzcyI6ICJzdXBhYmFzZS1kZW1vIiwKICAgICJpYXQiOiAxNjQxNzY5MjAwLAogICAgImV4cCI6IDE3OTk1MzU2MDAKfQ.DaYlNEoUrrEn2Ig7tqibS-PHK5vgusbcbo7X36XVt4Q"
    # JWT signing secret (only needed for self-hosted Supabase)
    jwtSecret: "your-super-secret-jwt-token-with-at-least-32-characters-long"

# =============================================================================
# RULEBRICKS APPLICATION
# =============================================================================
rulebricks:
  app:
    image:
      repository: index.docker.io/rulebricks/app
      pullPolicy: IfNotPresent

    logging:
      enabled: true
      # Leave empty to auto-discover Kafka from the kafka subchart (recommended)
      # Only set explicitly if using an external Kafka cluster
      kafkaBrokers: ""
      kafkaTopic: "logs"
      loggingDestination: "Console (stdout)"

  ingress:
    enabled: true
    className: traefik
    # Host is automatically configured from global.domain
    paths:
      - path: /
        pathType: Prefix

  redis:
    resources:
      requests:
        cpu: "200m"
        memory: "256Mi"
      limits:
        cpu: "500m"
        memory: "4Gi"
    persistence:
      enabled: true
      size: "4Gi"
      storageClass: gp3

  hps:
    enabled: true
    replicas: 2
    workers:
      enabled: true
      replicas: 4
      keda:
        enabled: true
        minReplicaCount: 4
        maxReplicaCount: 8
        pollingInterval: 10
        cooldownPeriod: 300
        lagThreshold: 8
        cpuThreshold: 25

# =============================================================================
# SELF-HOSTED DATABASE SETTINGS (Supabase)
# Set enabled: false to use an external Supabase instance instead
# =============================================================================
supabase:
  enabled: true
  secret:
    # JWT keys are sourced from global.supabase.* (anonKey, serviceKey, jwtSecret)
    db:
      username: "postgres"
      password: "postgres-password-change-me"
      database: "postgres"
    dashboard:
      username: "supabase"
      password: "dashboard-password-change-me"
    # SMTP credentials are sourced from global.smtp.user and global.smtp.pass
  # Database resource and storage configuration (for self-hosted)
  db:
    resources:
      requests:
        cpu: "500m"
        memory: "1Gi"
    persistence:
      enabled: true
      size: 10Gi
      storageClassName: gp3
  # Kong API Gateway ingress configuration
  kong:
    ingress:
      enabled: true
      className: traefik
      annotations: {}

# Message Queue (Kafka)
kafka:
  enabled: true
  controller:
    replicaCount: 1
    resources:
      requests:
        cpu: "500m"
        memory: "2Gi"
      limits:
        cpu: "2000m"
        memory: "3Gi"
    persistence:
      enabled: true
      size: 10Gi
      storageClass: gp3
    # JVM heap options for optimal performance
    # Note: Worth trying ZGC if you make the heap larger than 4GB
    heapOpts: "-Xmx1g -Xms1g -XX:+UseG1GC -XX:+AlwaysPreTouch"
    extraEnvVars:
      - name: KAFKA_CFG_QUEUED_MAX_REQUESTS
        value: "10000"
      - name: KAFKA_CFG_NUM_NETWORK_THREADS
        value: "8"
      - name: KAFKA_CFG_NUM_IO_THREADS
        value: "8"
      - name: KAFKA_CFG_SOCKET_SEND_BUFFER_BYTES
        value: "1048576"
      - name: KAFKA_CFG_SOCKET_RECEIVE_BUFFER_BYTES
        value: "1048576"
      - name: KAFKA_CFG_SOCKET_REQUEST_MAX_BYTES
        value: "209715200"
      - name: KAFKA_CFG_LOG_RETENTION_BYTES
        value: "4294967296"
      - name: KAFKA_CFG_LOG_SEGMENT_BYTES
        value: "1073741824"
  listeners:
    client:
      protocol: PLAINTEXT

# Ingress Controller (Traefik)
traefik:
  enabled: true
  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 2
  resources:
    requests:
      cpu: "100m"
      memory: "256Mi"
    limits:
      cpu: "1000m"
      memory: "2Gi"
  ports:
    web:
      port: 8000
      exposedPort: 80
    websecure:
      port: 8443
      exposedPort: 443
  persistence:
    enabled: false

# Autoscaling (KEDA)
keda:
  enabled: true
  crds:
    install: false # CRDs are managed in parent chart crds/ directory

# Certificate Management (cert-manager)
cert-manager:
  enabled: true
  installCRDs: false # CRDs are managed in parent chart crds/ directory

# =============================================================================
# LOGGING (Vector)
# Note: The bootstrap_servers will need to match your release name.
# If your release is named "rulebricks", use "rulebricks-kafka:9092"
# If using a different release name, update accordingly.
# =============================================================================
vector:
  enabled: true
  role: "Stateless-Aggregator"
  replicas: 2
  resources:
    requests:
      cpu: "50m"
      memory: "128Mi"
    limits:
      cpu: "200m"
      memory: "256Mi"
  service:
    enabled: true
    ports:
      - name: api
        port: 8686
        protocol: TCP
        targetPort: 8686
  # IMPORTANT: Update bootstrap_servers to match your helm release name
  # Format: <release-name>-kafka.<namespace>.svc.cluster.local:9092
  # For local cluster DNS, short name also works: <release-name>-kafka:9092
  customConfig:
    sources:
      kafka:
        type: kafka
        # This will be <release-name>-kafka:9092 - adjust if using different release name
        bootstrap_servers: "${KAFKA_BOOTSTRAP_SERVERS:-rulebricks-standalone-kafka:9092}"
        topics:
          - logs
        group_id: vector-consumers
        auto_offset_reset: latest
    sinks:
      console:
        type: console
        inputs:
          - kafka
        encoding:
          codec: json
      # ==== S3 Sink Example ====
      # To send logs to S3, uncomment and configure the following:
      # Requires IRSA (IAM Roles for Service Accounts) - see README.md for setup
      #
      # s3:
      #   type: aws_s3
      #   inputs:
      #     - kafka
      #   bucket: "your-logs-bucket"
      #   region: "us-east-1"
      #   key_prefix: "rulebricks/logs/%Y/%m/%d/"
      #   compression: gzip
      #   encoding:
      #     codec: json
      #   # Authentication via IRSA (recommended) - no credentials needed in config
      #   # Vector will use the IAM role attached to its service account
      #   #
      #   # Alternative: use static credentials (not recommended for production)
      #   # auth:
      #   #   access_key_id: "${AWS_ACCESS_KEY_ID}"
      #   #   secret_access_key: "${AWS_SECRET_ACCESS_KEY}"

# Monitoring (Prometheus only)
monitoring:
  enabled: false

kube-prometheus-stack:
  alertmanager:
    enabled: false
  grafana:
    enabled: false
  prometheus:
    prometheusSpec:
      retention: 30d
      storageSpec:
        volumeClaimTemplate:
          spec:
            storageClassName: gp3
            accessModes:
              - ReadWriteOnce
            resources:
              requests:
                storage: 50Gi
      remoteWrite: []
